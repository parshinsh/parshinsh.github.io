---
layout: homepage
---

## About Me

Hi! I’m a final-year PhD student in Computer Science at Virginia Tech, advised by Prof. [Chandan Reddy](https://people.cs.vt.edu/reddy/). My research interests center on **understanding how language models reason**, **adapt to new scenarios**, and **how these capabilities can be harnessed toward scientific and open-ended discovery**. 
<!-- I mostly focus on developing better algorithms for language models to handle symbolic reasoning and scientific discovery tasks, while studying their current limitations. -->


During my PhD, I've been fortunate to have my work recognized through fellowships and awards, including the [Pratt Fellowship](https://ece.vt.edu/fellowships.html), and two papers nominated as **Oral** at [ICML 2025](https://openreview.net/forum?id=SyQPiZJVWY) (top 1%) and [ICLR 2025](https://openreview.net/forum?id=m2nmp8P5in) (top 1.8%). My research has also been featured in [Nature](https://www.nature.com/articles/d41586-025-02616-5), [Women in AI Research Podcast](https://www.youtube.com/watch?v=qD0_aHQvdR8&t=3s), [CNBC](https://www.cnbc.com/video/2025/06/26/why-the-ai-industry-has-a-reasoning-problem.html), [HackerNews](https://news.ycombinator.com/item?id=44203562), [Forbes](https://www.forbes.com/sites/corneliawalther/2025/06/09/intelligence-illusion-what-apples-ai-study-reveals-about-reasoning/), [Mashable](https://mashable.com/article/apple-research-ai-reasoning-models-collapse-logic-puzzles), [The Guardian](https://www.theguardian.com/technology/2025/jun/09/apple-artificial-intelligence-ai-study-collapse), [New York Times](https://www.nytimes.com/2025/06/13/technology/meta-scale-ai-super-intelligence-lab.html#:~:text=%E2%80%9CThese%20are%20great%20tools%2C%E2%80%9D,lab?), [Washington Post](https://www.washingtontimes.com/news/2025/jun/9/apple-making-ai-accessible-developers-researchers-cast-doubt-large/) etc. 
I was fortunate to have the chance of working with brilliant researchers in the field whose mentorship and collaboration has shaped my research journey: [Chandan Reddy](https://creddy.net/) (VT), [Mehrdad Farajtabar](https://sites.google.com/view/mehrdad) (Apple), [Samy Bengio](https://bengio.abracadoudou.com/) (Apple), [Iman Mirzadeh](https://imirzadeh.me/) (Apple), [Amir Barati Farimani](https://sites.google.com/view/barati) (CMU), [Yunyao Li](https://yunyaoli.github.io/) (Adobe), [Shashank Gupta](https://shashankgupta.info/) (AI2), and [Khoa Doan](https://mail-research.com/) (VinUniversity). 


<!-- . I have worked with -->

<!-- I’m grateful to the brilliant researchers and collaborators  -->

Before starting my PhD, I completed my MS in Operations Research at Virginia Tech, and obtained my BS from [Sharif University of Technology](https://en.sharif.edu/). 

If you're interested in my research on open-ended reasoning and discovery with LLMs, would like to discuss relevant topics, or explore potential collaborations, please feel free to get in touch :) - I am best reached by email at [parshinshojaee@vt.edu](mailto:parshinshojaee@vt.edu)


<!-- I’m interested in how language models reason, adapt to new situations, and how these abilities can be used for scientific discovery and other open-ended problems. -->

<!-- My research focus is on understanding how frontier language models reason, adapt to new scenarios, and how these capabilities can be harnessed toward scientific and open-ended discovery.  -->


<!-- My research focus is on cultural inclusivity and diversity within multimodal (vision-text) generation and understanding, but I also explore image and video generation more broadly. In my PhD, I'm revisiting the age old problem of translation, and exploring how it extends to multiple modalities (focus on visual). Checkout this github repo where I've been collecting resources for cultural NLP and please feel free to send a PR to add relevant material! -->



<!-- My primary research topic is AI for symbolic generation (code, math, reasoning) and its potential for scientific discovery.  -->
<!-- I mostly focus on developing better algorithms for language models to handle symbolic reasoning and scientific discovery tasks, while studying their current limitations. -->
<!-- During my PhD, I have also pursued research internships at [Apple](https://machinelearning.apple.com/) (2025) and [Adobe](https://www.adobe.com/home) (2024).  -->


<!-- I was a summer ML intern at [Gilead Sciences](https://www.gilead.com/) (2022),  -->

<!-- When I'm not coding or doing AI research, you'll find me playing Tar and Setar (think Persian guitars with their own unique twist) or exploring different music genres. -->


<!-- I am also currently a research intern at [Apple](https://machinelearning.apple.com/), where I'm focused on reasoning with LLMs.  -->




<!-- ## Research Interests -->
<!-- My primary research interests revolve around AI for Science and Engineering. Most of my works fall into one of these categories: -->
<!-- My primary research interests revolve around AI for symbolic generation (code, math & reasoning) and its potentials for scientific discovery. Most of my works fall into one of these categories: -->
<!-- Most of my works focus on extending Reinforcement Learning and Transformer models to non-text domains, falling into one of these categories: -->
<!-- - **AI for Math**, with a focus on uncovering hidden mathematical laws within data (equation discovery, symbolic regression)
- **AI for Code**, with a focus on automating program synthesis, contextual code generation, and neuro-symbolic programming
 -->





## News


<div class="news-scrollable">
  <ul>
    <li><strong>[Dec 2025]</strong> Preprint of <a href="https://arxiv.org/abs/2512.15567">SDE-Harness</a>, our new large-scale study on evaluating LLMs in scientific discovery, is now on arXiv.</li>

    <li><strong>[Dec 2025]</strong> Presenting our NeurIPS 2025 poster on <a href="https://www.youtube.com/watch?v=qD0_aHQvdR8">Women in AI Research Podcast</a>!</li>

    <li><strong>[Nov 2025]</strong> Our paper <a href="https://openreview.net/forum?id=fbrmmokJiU">DecAEvolve (Decompose, Adapt, and Evolve)</a>, a new LLM-based evolutionary discovery framework augmented with adaptation and test-time training, is accepted to <a href="https://mathai2025.github.io/">Math-AI</a> and <a href="https://ai4sciencecommunity.github.io/neurips25">AI4Science</a> Workshops at <strong>NeurIPS 2025</strong>.</li>

    <li><strong>[Sep 2025]</strong> Our paper <a href="https://arxiv.org/abs/2506.06941">The Illusion of Thinking</a> is accepted to <a href="https://neurips.cc/"><strong>NeurIPS 2025</strong></a> main track! See you in San Diego!</li>

    <li><strong>[June 2025]</strong> My Apple internship project <a href="https://arxiv.org/abs/2506.06941">The Illusion of Thinking? Understanding Reasoning Models via the Lens of Problem Complexity</a> is now on arXiv.</li>

    <li><strong>[May 2025]</strong> Our paper <a href="https://arxiv.org/abs/2504.10415">LLM-SRBench</a> is accepted to <a href="https://icml.cc/"><strong>ICML 2025</strong></a> as <strong style="color:red;">Oral</strong>!</li>

    <li><strong>[Apr 2025]</strong> Preprint of <a href="https://arxiv.org/abs/2504.10415">LLM-SRBench</a>, our new benchmark targeting memorization issues in LLM-based scientific discovery, is now on arXiv.</li>

    <li><strong>[Feb 2025]</strong> Excited to start my research internship at <a href="https://machinelearning.apple.com/">Apple</a>!</li>

    <li><strong>[Feb 2025]</strong> I’ll be presenting our tutorial “<a href="https://symbolicregression2025.github.io/">Towards Interpretability and Automated Scientific Discovery</a>” at <a href="https://aaai.org/conference/aaai/aaai-25/"><strong>AAAI 2025</strong></a>. See you in Philadelphia!</li>

    <li><strong>[Jan 2025]</strong> Our <a href="https://arxiv.org/abs/2404.18400">LLM-SR</a> paper on LLM agents + evolutionary search for scientific discovery is accepted to <a href="https://iclr.cc/"><strong>ICLR 2025</strong></a> as <strong style="color:red;">Oral</strong>!</li>

    <li><strong>[Dec 2024]</strong> My Adobe internship project <a href="https://arxiv.org/abs/2501.14998">Federated RAG for Multi-Source QA</a> is now on arXiv.</li>

    <li><strong>[Nov 2024]</strong> Our position paper on <a href="https://arxiv.org/abs/2412.11427">AI for Scientific Discovery</a> is accepted to <a href="https://aaai.org/conference/aaai/aaai-25/"><strong>AAAI 2025</strong></a>!</li>

    <li><strong>[May 2024]</strong> Excited to start my internship at <a href="https://www.adobe.com/home">Adobe</a> this summer!</li>

    <li><strong>[Jan 2024]</strong> Our <a href="https://openreview.net/forum?id=KZSEgJGPxu">SNIP (Symbolic-Numeric Pretraining)</a> paper is accepted to <a href="https://iclr.cc/Conferences/2024"><strong>ICLR 2024</strong></a> as <strong style="color:red;">Spotlight</strong>!</li>

    <li><strong>[Dec 2023]</strong> I will be at NeurIPS 2023 in New Orleans, presenting our <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html">TPSR</a> paper.</li>

    <li><strong>[Sep 2023]</strong> Our <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html">TPSR</a> paper is accepted to <a href="https://nips.cc/"><strong>NeurIPS 2023</strong></a>!</li>

    <li><strong>[Jul 2023]</strong> Our <a href="https://openreview.net/forum?id=0XBuaxqEcG">PPOCoder</a> paper is accepted to <a href="https://jmlr.org/tmlr/"><strong>TMLR</strong></a>!</li>
  </ul>
</div>



<!-- <div class="news-scrollable">

- **[Dec 2025]**  Preprint of [SDE-Harness](https://arxiv.org/abs/2512.15567), our new large-scale study on evaluating LLMs in scientific discovery, is now on arxiv.
- **[Dec 2025]**  Presenting our NeurIPS 2025 poster on [Women in AI Research Podcast](https://www.youtube.com/watch?v=qD0_aHQvdR8)!
- **[Nov 2025]**  Our paper [DecAEvolve (Decompose, Adapt, and Evolve)](https://openreview.net/forum?id=fbrmmokJiU), a new LLM-based evolutionary discovery framework augmented with adaptation and test-time training, is accepted to [Math-AI](https://mathai2025.github.io/) and [AI4Science](https://ai4sciencecommunity.github.io/neurips25) Workshops at **NeurIPS 2025**.
- **[Sep 2025]**  Our paper [The Illusion of Thinking](https://arxiv.org/abs/2506.06941) is accepted to [**NeurIPS 2025**](https://neurips.cc/) main track! See you in San Diego!
- **[June 2025]**  My Apple internship project [The Illusion of Thinking? Understanding Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.06941) is now on arxiv.
- **[May 2025]**  Our paper [LLM-SRBench](https://arxiv.org/abs/2504.10415) is accepted to [**ICML 2025**](https://icml.cc/) as <strong style="color: red;">Oral</strong>! 
- **[Apr 2025]**  Preprint of [LLM-SRBench](https://arxiv.org/abs/2504.10415), our new benchmark targetting memorization issue in LLM-based scientific disocvery, is now on arxiv.  
- **[Feb 2025]**  Excited to start my research internship at [Apple](https://machinelearning.apple.com/)!
- **[Feb 2025]**  I'll be presenting our tutorial of “[Towards Interpretability and Automated Scientific Discovery](https://symbolicregression2025.github.io/)” at [**AAAI 2025**](https://aaai.org/conference/aaai/aaai-25/). See you in Philadelphia!
- **[Jan 2025]** Our [LLM-SR](https://arxiv.org/abs/2404.18400) paper on LLM agents + evolutionary search for scientific discovery is accepted to [**ICLR 2025**](https://iclr.cc/) as <strong style="color: red;">Oral</strong>!
- **[Dec 2024]** My Adobe internship project [Federated RAG for Multi-Source QA](https://arxiv.org/abs/2501.14998) is now on arxiv.
- **[Nov 2024]** Our position paper on the potentials and challenges of [AI for Scientific Discovery](https://arxiv.org/abs/2412.11427) is accepted to [**AAAI 2025**](https://aaai.org/conference/aaai/aaai-25/)!
- **[May. 2024]** I’m excited to start my internship at [Adobe](https://www.adobe.com/home) in this summer!
- **[Jan. 2024]** Our [SNIP (Symbolic-Numeric Pretraining)](https://openreview.net/forum?id=KZSEgJGPxu) paper on mathematical discovery with multi-modal latent reasoning is accepted to [**ICLR 2024**](https://iclr.cc/Conferences/2024) as <strong style="color: red;">Spotlight</strong>!
- **[Dec. 2023]** I will be at NeurIPS 2023 in New Orleans, presenting our [TPSR](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html) paper. See you in New Orleans! 
- **[Sep. 2023]** Our paper [TPSR](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8ffb4e3118280a66b192b6f06e0e2596-Abstract-Conference.html) on mathematical discovery with language model + MCTS lookahead planning is accepted to [**NeurIPS 2023**](https://nips.cc/)!
- **[Jul. 2023]** Our paper [PPOCoder](https://openreview.net/forum?id=0XBuaxqEcG) on reinforcement learning for program synthesis is accepted to [**TMLR**](https://jmlr.org/tmlr/)!

</div> -->



<!-- - **[Dec. 2022]** Our paper [GRAM-ODE](https://openreview.net/forum?id=Oq5XKRVYpQ) on forecasting with graph ODEs is accepted to [**TMLR**](https://jmlr.org/tmlr/)!  --> 

<!-- - **[Apr. 2024]** Our [LLM-SR](https://arxiv.org/abs/2404.18400) paper on using LLMs + evolutionary search for scientific discovery is now on arXiv. -->


<!-- equation disocvery with transformers and planning  -->

<!-- - **[May. 2022]** I’m thrilled to start my internship at [Gilead Sciences](https://www.gilead.com/) in this upcoming summer 2022! -->
<!-- - **[Jan. 2021]**  I started my PhD at [Virginia Tech](https://cs.vt.edu/). -->
<!-- - **[Apr. 2019]** One paper was accepted to TMLR 2023. -->


<!-- https://tmlr.infinite-conf.org/paper_pages/0XBuaxqEcG.html -->


{% include_relative _includes/publications.md %}

{% include_relative _includes/services.md %}


## A little more about me
When I'm not into AI research, I enjoy exploring all kinds of music and playing [Tar](https://www.youtube.com/watch?v=XXYy_bmlUpg) and [Setar](https://www.youtube.com/watch?app=desktop&v=enL-YQKihvg) instruments (Persian guitars with their own unique twist). Recently, I'm also into hiking new trails, and trying to be good at gardening :D 

